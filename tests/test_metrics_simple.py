#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è Metrics –º–æ–¥—É–ª—è –±–µ–∑ PyTorch –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import unittest
import sys
import os
import numpy as np
from unittest.mock import Mock, patch, MagicMock

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

class TestMetricsSimple(unittest.TestCase):
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è Metrics –º–æ–¥—É–ª—è"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
        try:
            from core.utils.metrics import (
                mean_absolute_error, root_mean_squared_error, 
                mean_absolute_percentage_error, direction_hit_rate,
                confusion_matrix, precision_recall_f1,
                roc_auc_score, pr_auc_score, value_at_risk, 
                expected_shortfall, win_rate, turnover_rate,
                exposure_stats, equity_curve, max_drawdown,
                sharpe_ratio, sortino_ratio, aggregate_returns_equal_weight,
                calculate_portfolio_metrics, calculate_regression_metrics,
                calculate_classification_metrics, calculate_risk_metrics,
                calculate_trading_metrics
            )
            self.metrics_module = sys.modules['core.utils.metrics']
        except ImportError as e:
            self.skipTest(f"Metrics –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    
    def test_metrics_functions_exist(self):
        """–¢–µ—Å—Ç –Ω–∞–ª–∏—á–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π metrics"""
        required_functions = [
            'mean_absolute_error',
            'root_mean_squared_error', 
            'mean_absolute_percentage_error',
            'direction_hit_rate',
            'confusion_matrix',
            'precision_recall_f1',
            'roc_auc_score',
            'pr_auc_score',
            'value_at_risk',
            'expected_shortfall',
            'win_rate',
            'turnover_rate',
            'exposure_stats',
            'equity_curve',
            'max_drawdown',
            'sharpe_ratio',
            'sortino_ratio',
            'aggregate_returns_equal_weight',
            'calculate_portfolio_metrics',
            'calculate_regression_metrics',
            'calculate_classification_metrics',
            'calculate_risk_metrics',
            'calculate_trading_metrics'
        ]
        
        for func_name in required_functions:
            self.assertTrue(hasattr(self.metrics_module, func_name), 
                          f"–§—É–Ω–∫—Ü–∏—è {func_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    def test_basic_regression_metrics(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        y_true = [1.0, 2.0, 3.0, 4.0]
        y_pred = [1.1, 1.9, 3.1, 3.9]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º MAE
        mae = self.metrics_module.mean_absolute_error(y_true, y_pred)
        self.assertIsInstance(mae, (int, float))
        self.assertGreaterEqual(mae, 0)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º RMSE
        rmse = self.metrics_module.root_mean_squared_error(y_true, y_pred)
        self.assertIsInstance(rmse, (int, float))
        self.assertGreaterEqual(rmse, 0)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º MAPE
        mape = self.metrics_module.mean_absolute_percentage_error(y_true, y_pred)
        self.assertIsInstance(mape, (int, float))
        self.assertGreaterEqual(mape, 0)
    
    def test_basic_classification_metrics(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        y_true = [0, 1, 0, 1, 0]
        y_pred = [0, 1, 0, 0, 1]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º confusion matrix
        cm = self.metrics_module.confusion_matrix(y_true, y_pred, [0, 1])
        self.assertIsInstance(cm, list)
        self.assertEqual(len(cm), 2)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º precision_recall_f1
        prf = self.metrics_module.precision_recall_f1(cm)
        self.assertIsInstance(prf, dict)
        self.assertIn('macro', prf)
        self.assertIn('micro', prf)
    
    def test_basic_risk_metrics(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞"""
        returns = [-0.02, -0.01, 0.0, 0.01, 0.02, 0.03, 0.04]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º VaR
        var_95 = self.metrics_module.value_at_risk(returns, 0.95)
        self.assertIsInstance(var_95, (int, float))
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º Expected Shortfall
        es = self.metrics_module.expected_shortfall(returns, 0.95)
        self.assertIsInstance(es, (int, float))
    
    def test_basic_trading_metrics(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        returns = [-0.01, 0.02, -0.005, 0.015, -0.02, 0.01]
        positions = [0.1, 0.2, 0.15, 0.25, 0.3]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º win rate
        wr = self.metrics_module.win_rate(returns)
        self.assertIsInstance(wr, (int, float))
        self.assertGreaterEqual(wr, 0)
        self.assertLessEqual(wr, 1)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º turnover rate
        turnover = self.metrics_module.turnover_rate(positions)
        self.assertIsInstance(turnover, (int, float))
        self.assertGreaterEqual(turnover, 0)
    
    def test_basic_portfolio_metrics(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        returns = [0.01, -0.005, 0.02, -0.01]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º equity curve
        equity = self.metrics_module.equity_curve(returns, 1000.0)
        self.assertIsInstance(equity, list)
        self.assertEqual(len(equity), len(returns) + 1)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º max drawdown
        mdd = self.metrics_module.max_drawdown(equity)
        self.assertIsInstance(mdd, (int, float))
        self.assertLessEqual(mdd, 0)  # Drawdown should be negative
    
    def test_utility_functions(self):
        """–¢–µ—Å—Ç —É—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π"""
        y_true = [1.0, 2.0, 3.0, 4.0, 5.0]
        y_pred = [1.1, 1.9, 3.1, 3.9, 5.1]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º calculate_regression_metrics
        reg_metrics = self.metrics_module.calculate_regression_metrics(y_true, y_pred)
        self.assertIsInstance(reg_metrics, dict)
        self.assertIn('mae', reg_metrics)
        self.assertIn('rmse', reg_metrics)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º calculate_risk_metrics
        returns = [-0.02, -0.01, 0.0, 0.01, 0.02, 0.03, 0.04]
        positions = [0.1, 0.2, 0.15, 0.25, 0.3, 0.35, 0.4]
        risk_metrics = self.metrics_module.calculate_risk_metrics(returns, positions, 0.95)
        self.assertIsInstance(risk_metrics, dict)
        self.assertIn('var', risk_metrics)
        self.assertIn('expected_shortfall', risk_metrics)

def main():
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤"""
    print("üß™ –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ Metrics –º–æ–¥—É–ª—è...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
    test_suite = unittest.TestSuite()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç—ã
    loader = unittest.TestLoader()
    test_suite.addTest(loader.loadTestsFromTestCase(TestMetricsSimple))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"\n–¢–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã: {result.testsRun} —Ç–µ—Å—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
    print(f"–û—à–∏–±–æ–∫: {len(result.errors)}")
    print(f"–ü—Ä–æ–≤–∞–ª–æ–≤: {len(result.failures)}")
    
    if result.wasSuccessful():
        print("‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        return 0
    else:
        print("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
        return 1

if __name__ == '__main__':
    exit_code = main()
    assert exit_code == 0, "Metrics simple tests failed"
